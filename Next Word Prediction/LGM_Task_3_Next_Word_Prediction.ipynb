{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGM Task 3_Next Word Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LetsGrowMore**\n",
        "\n",
        "LGMVIP May-22 \n",
        "- Likhita Vaka\n",
        "\n",
        "**Advanced Level Task :**\n",
        "# **TASK 3 - Next Word Prediction**\n",
        "**DataSet Link:**\n",
        "https://drive.google.com/file/d/1GeUzNVqiixXHnTl8oNiQ2W3CynX_lsu2/view\n"
      ],
      "metadata": {
        "id": "pa498z_XNCqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "yX5qwiHCONJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "metadata": {
        "id": "DgkWfbSKOUds"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset from system**"
      ],
      "metadata": {
        "id": "BMJ6lhufOwMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = open(\"/content/T3.txt\", encoding='UTF-8').read().lower() #reading the text file"
      ],
      "metadata": {
        "id": "pAjSWIp1OxOi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Storing relevant data only (for better accuracy)**"
      ],
      "metadata": {
        "id": "tgk9aLgeQzs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txtf=text_file[1273:] #storing the relevant text by slicing the about intro,preface,cover,index details from the dataset\n"
      ],
      "metadata": {
        "id": "loqmsmIwQ6L7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Length of text present in file :', len(txtf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOG-wccYQ9hD",
        "outputId": "bed32a0c-2479-43d5-85a1-2af25896562b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text present in file : 580615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the dataset into single words in order**"
      ],
      "metadata": {
        "id": "Cxqdpz7ZRCHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=RegexpTokenizer(r'\\w+')\n",
        "wrds = tokenizer.tokenize(txtf)"
      ],
      "metadata": {
        "id": "vMJvPHX4RDG-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making a dictionary containing every word in the data**"
      ],
      "metadata": {
        "id": "GPv4yknHRGnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uq_wrds= np.unique(wrds) #storing all unique words inside a list\n",
        "uq_wrd_index= dict((j,i) for i,j in enumerate(uq_wrds)) #creating a dictionary with keys(list of unique words) and values(all words present in the datase"
      ],
      "metadata": {
        "id": "GXXK9oQbRJ79"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "BeN5UTPKRMfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrd_len=5\n",
        "prev_wrds=[]\n",
        "next_wrds=[]\n",
        "for i in range(len(wrds)-wrd_len):\n",
        "    prev_wrds.append(wrds[i:(i+wrd_len)])\n",
        "    next_wrds.append(wrds[i+wrd_len])\n",
        "print(prev_wrds[0])\n",
        "print('\\n',next_wrds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZK_dfkFRNYF",
        "outputId": "ae70332f-c3f2-448c-91e0-8c94cbba3861"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to', 'sherlock', 'holmes', 'she', 'is']\n",
            "\n",
            " always\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a array to store the features\n",
        "X = np.zeros((len(prev_wrds), wrd_len, len(uq_wrds)), dtype=bool)"
      ],
      "metadata": {
        "id": "pGC-tdAnRS7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating another array to store the corresponding label\n",
        "Y = np.zeros((len(next_wrds), len(uq_wrds)), dtype=bool)"
      ],
      "metadata": {
        "id": "sGaGzs5gRVDm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing \n",
        "for i, each_wrds in enumerate(prev_wrds):\n",
        "    for j, each_wrds in enumerate(each_wrds):\n",
        "        X[i, j, uq_wrd_index[each_wrds]] = 1\n",
        "    Y[i, uq_wrd_index[next_wrds[i]]] = 1"
      ],
      "metadata": {
        "id": "gFOvmEDdRXOU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0][0])  #a look at a single sequence of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4Z5BdzKRZOK",
        "outputId": "5cfd0bac-5db2-4754-cf4c-44cd3a71953b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False ... False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bulding model**"
      ],
      "metadata": {
        "id": "hm4_sJA2RbO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(128, input_shape=(wrd_len, len(uq_wrds))))  #using LSTM model, a powerful Recurrent Neural Network(RNN).\n",
        "model.add(Dense(len(uq_wrds)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "BVSpKIZMRcFA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "yWcvXFrmRftq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history= model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=5, shuffle=True).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Zk1RWwRgjl",
        "outputId": "4ca697ae-00cc-4c18-b6fd-aebca14c40a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "810/810 [==============================] - 249s 304ms/step - loss: 6.0081 - accuracy: 0.1064 - val_loss: 7.2158 - val_accuracy: 0.1025\n",
            "Epoch 2/5\n",
            "810/810 [==============================] - 238s 294ms/step - loss: 5.7761 - accuracy: 0.1474 - val_loss: 7.9748 - val_accuracy: 0.0932\n",
            "Epoch 3/5\n",
            "810/810 [==============================] - 239s 295ms/step - loss: 5.7443 - accuracy: 0.1748 - val_loss: 8.2851 - val_accuracy: 0.0985\n",
            "Epoch 4/5\n",
            "810/810 [==============================] - 237s 293ms/step - loss: 5.4096 - accuracy: 0.2114 - val_loss: 8.6177 - val_accuracy: 0.0972\n",
            "Epoch 5/5\n",
            "810/810 [==============================] - 237s 293ms/step - loss: 5.0581 - accuracy: 0.2498 - val_loss: 8.8039 - val_accuracy: 0.0897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the model for future use**"
      ],
      "metadata": {
        "id": "JkIerwyiS3rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model= load_model('keras_next_word_model.h5')\n",
        "history= pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "3_x_iw0zS4jp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the Model**"
      ],
      "metadata": {
        "id": "CzsC8hlCS6ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(txtf):\n",
        "    x=np.zeros((1, wrd_len, len(uq_wrds)))\n",
        "    for t, word in enumerate(txtf.split()):\n",
        "        print(word)\n",
        "        x[0, t, uq_wrd_index[word]] = 1\n",
        "    return x\n",
        "prepare_input(\"That which does not give\".lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFa3QGdFS-Kl",
        "outputId": "3cbc1014-8bbb-4425-ab61-c3ee46eda782"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that\n",
            "which\n",
            "does\n",
            "not\n",
            "give\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#funtion for returning samples\n",
        "def sample(preds, top_n=3): \n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "metadata": {
        "id": "dd7tAqNzTCNo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funtion for prediction model\n",
        "def predict_completions(txt,n=3):\n",
        "    if txt==\"\":\n",
        "        return(\"0\")\n",
        "    x=prepare_input(txt)\n",
        "    preds=model.predict(x, verbose=0)[0]\n",
        "    next_indices=sample(preds,n)\n",
        "    return [uq_wrds[idx] for idx in next_indices]"
      ],
      "metadata": {
        "id": "mH50GOfCTDzp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Result**"
      ],
      "metadata": {
        "id": "DUDsL4WlTHWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = input(\"Enter a sentence:- \")\n",
        "seq = \" \".join(tokenizer.tokenize(sent.lower())[0:5])  #using only first 5 words of the input\n",
        "pc=predict_completions(seq, 10)  #creating a list of 10 predicted words using the model\n",
        "print(\"Next predicted words:\",pc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqjE5CMLTJc0",
        "outputId": "2a40be0f-bdd3-41de-9ce0-6c665e657122"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence:- Indeed, I should have thought a little more\n",
            "indeed\n",
            "i\n",
            "should\n",
            "have\n",
            "thought\n",
            "Next predicted words: ['that', 'a', 'of', 'the', 'her', 'it', 'in', 'he', 'my', 'what']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word 'a' is after the word 'thought' in the input and in the list of predicted words, word 'a' is present at 2nd position.\n",
        "\n",
        "Therefore, we can conclude that our model gave a correct prediction."
      ],
      "metadata": {
        "id": "9Xgi0TzRXcks"
      }
    }
  ]
}